{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finance Chatbot\n",
    "This is a chatbot to assist kenyans know more about the banks in the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/marwa254/.cache/huggingface/datasets/json/default-1409bde2ada223f8/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41172463f033494095c42534dd59697e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "\n",
    "dataset = load_dataset('json', data_files='./data/intents.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and the model\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"hf-internal-testing/llama-tokenizer\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"huggyllama/llama-7b\")\n",
    "\n",
    "input_text = \"Tell me about the major banks in Kenya.\"\n",
    "\n",
    "#tokenize\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "#text generation\n",
    "output = model.generate(**inputs, max_length=100, do_sample=True)\n",
    "\n",
    "#decode\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_token = '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'\n",
    "token_chacha = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import streamlit as st \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:08:04.270 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/marwa254/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator(_root_container=1, _parent=DeltaGenerator())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import streamlit as st\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Hugging Face API settings\n",
    "API_URL = \"https://api-inference.huggingface.co/models/huggyllama/llama-7b\"\n",
    "headers = {\"Authorization\": token_chacha}\n",
    "\n",
    "# Function to query Hugging Face API\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Function to process and return response\n",
    "def get_response(input_text):\n",
    "    response = query({\"inputs\": input_text})\n",
    "    # Extract generated text from response JSON\n",
    "    return response[0]['generated_text'] if 'generated_text' in response[0] else response\n",
    "\n",
    "# Streamlit app layout\n",
    "st.title(\"Kenya Finance Chatbot\")\n",
    "st.write(\"Ask anything about banks and financial services in Kenya!\")\n",
    "\n",
    "# Input box for the user's question\n",
    "user_input = st.text_input(\"Enter your question:\")\n",
    "\n",
    "# When the user clicks the 'Submit' button\n",
    "if st.button(\"Submit\"):\n",
    "    if user_input:\n",
    "        with st.spinner('Thinking...'):\n",
    "            # Get the response from the chatbot\n",
    "            response = get_response(user_input)\n",
    "        # Display the response\n",
    "        st.write(\"Chatbot: \", response)\n",
    "    else:\n",
    "        st.write(\"Please enter a question.\")\n",
    "\n",
    "# About section\n",
    "st.sidebar.title(\"About\")\n",
    "st.sidebar.info(\"\"\"\n",
    "This finance chatbot provides information on banks in Kenya. Powered by Hugging Face's LLaMA model.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
